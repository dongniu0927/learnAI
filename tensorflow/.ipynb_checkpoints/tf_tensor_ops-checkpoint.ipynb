{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Tensor Ops\n",
    "\n",
    "介绍tf中跟tensor操作有关的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1645: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.InteractiveSession()\n",
    "init=tf.global_variables_initializer()\n",
    "init.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [tf.concat()]((https://www.tensorflow.org/api_docs/python/tf/concat))\n",
    "\n",
    "可以**在某个维度上连接两个Tensor**，其函数原型为：\n",
    "\n",
    "```bash\n",
    "tf.concat(\n",
    "    values,\n",
    "    axis,\n",
    "    name='concat'\n",
    ")\n",
    "```\n",
    "\n",
    "- `values`: 一个Tensor列表或元组，比如：`[Tensor1, Tensor2]`表示要连接这两个`Tensor`;\n",
    "- `axis`: 想在哪一维度上做连接;\n",
    "\n",
    "实际上本函数操作表现为**对应维度的拼接**，使用例子如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1  2  7  4]\n",
      "  [ 2  3  8  4]]\n",
      "\n",
      " [[ 4  4  2 10]\n",
      "  [ 5  3 15 11]]]\n"
     ]
    }
   ],
   "source": [
    "t1 = [[[1, 2], [2, 3]], [[4, 4], [5, 3]]]  # shape=(2, 2, 2)\n",
    "t2 = [[[7, 4], [8, 4]], [[2, 10], [15, 11]]]  # shape=(2, 2, 2)\n",
    "\n",
    "_axis = 2  # 改变这个值查看效果\n",
    "\n",
    "# 第_axis维上拼接\n",
    "res_op = tf.concat([t1, t2], axis=_axis)  \n",
    "print(res_op.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [tf.transpose](https://www.tensorflow.org/api_docs/python/tf/transpose)\n",
    "\n",
    "对张量中的维度进行调换，当张量为2维，相当于转置。其函数原型为：\n",
    "\n",
    "```bash\n",
    "tf.transpose(\n",
    "    a,\n",
    "    perm=None,\n",
    "    name='transpose',\n",
    "    conjugate=False\n",
    ")\n",
    "```\n",
    "\n",
    "- `a`: 希望进行调整的张量。\n",
    "- `perm`: 调整后的维度排列，默认值为`[n-1, ...,0]`。\n",
    "- `conjugate`: 是否进行共轭变化，当置为`True`且`a`张量是复数类型的时候，会对`a`进行共轭转置。\n",
    "\n",
    "下面有一种`transpose`的使用的场景：\n",
    "\n",
    "```python\n",
    "# Assume features is of size [N, H, W, C] (batch_size, height, width, channels).\n",
    "# Transpose it to [N, C, H, W], then reshape to [N * C, H * W].\n",
    "features = tf.reshape(tf.transpose(features, [0, 3, 1, 2]), [N * C, H * W])\n",
    "```\n",
    "\n",
    "下面给出了具体的使用例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4]\n",
      " [2 5]\n",
      " [3 6]]\n",
      "\n",
      "[[1 4]\n",
      " [2 5]\n",
      " [3 6]]\n",
      "\n",
      "[[[ 1  4]\n",
      "  [ 2  5]\n",
      "  [ 3  6]]\n",
      "\n",
      " [[ 7 10]\n",
      "  [ 8 11]\n",
      "  [ 9 12]]]\n"
     ]
    }
   ],
   "source": [
    "# 简单例子\n",
    "x = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "y = tf.transpose(x)\n",
    "print(y.eval())\n",
    "print()\n",
    "\n",
    "y = tf.transpose(x, perm=[1, 0])  # 跟上面效果一样\n",
    "print(y.eval())\n",
    "print()\n",
    "\n",
    "# 复杂例子\n",
    "x = tf.constant([[[ 1,  2,  3],\n",
    "                  [ 4,  5,  6]],\n",
    "                 [[ 7,  8,  9],\n",
    "                  [10, 11, 12]]])  # shape is (2, 2, 3)\n",
    "y = tf.transpose(x, perm=[0, 2, 1])  # 将1,2维转置，shape is (2, 3, 2)\n",
    "print(y.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [tf.convert_to_tensor()](https://www.tensorflow.org/api_docs/python/tf/convert_to_tensor)\n",
    "\n",
    "将一个非Tensor数据值转化为`Tensor`类型。 其函数原型为:\n",
    "\n",
    "```bash\n",
    "tf.convert_to_tensor(\n",
    "    value,\n",
    "    dtype=None,\n",
    "    name=None,\n",
    "    preferred_dtype=None\n",
    ")\n",
    "```\n",
    "\n",
    "- `value`: 任意一个python类型的数据值；\n",
    "- `dtype`: 建立的tensor的数据类型,如果缺失将会根据原始值进行推测；\n",
    "- `preferred_dtype`: `dtype`是`None`的时候使用；\n",
    "\n",
    "使用例子如下:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_2:0\", shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = [[1.0, 2.0], [3.0, 4.0]]\n",
    "print(tf.convert_to_tensor(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [tf.cast](https://www.tensorflow.org/api_docs/python/tf/cast)\n",
    "\n",
    "转换一个Tensor的数据类型。 其函数原型为:\n",
    "\n",
    "```bash\n",
    "tf.cast(\n",
    "    x,\n",
    "    dtype,\n",
    "    name=None\n",
    ")\n",
    "```\n",
    "- `x`: 需要转换的Tensor `x`;\n",
    "- `dtype`: 需要转化为什么类型;\n",
    "\n",
    "使用例子如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Cast:0\", shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1.8, 2.2], dtype=tf.float32)\n",
    "y = tf.cast(x, tf.int32)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [tf.get_variable](https://www.tensorflow.org/api_docs/python/tf/get_variable)\n",
    "\n",
    "获取一个已经存在的变量或者建立一个新的变量. 这个函数可以配合variable scope进行变量重用. 其函数原型为:\n",
    "```bash\n",
    "tf.get_variable(\n",
    "    name,\n",
    "    shape=None,\n",
    "    dtype=None,\n",
    "    initializer=None,\n",
    "    regularizer=None,\n",
    "    trainable=None,\n",
    "    collections=None,\n",
    "    caching_device=None,\n",
    "    partitioner=None,\n",
    "    validate_shape=True,\n",
    "    use_resource=None,\n",
    "    custom_getter=None,\n",
    "    constraint=None,\n",
    "    synchronization=tf.VariableSynchronization.AUTO,\n",
    "    aggregation=tf.VariableAggregation.NONE\n",
    ")\n",
    "```\n",
    "- `name`: 一个新的或者已存在的变量名称;\n",
    "- `shape`: 变量的shape;\n",
    "- `dtype`: 变量的数据类型;\n",
    "- `initializer`: 变量初始化器;\n",
    "- `trainable`: 是否要训练这个变量;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo():\n",
    "    with tf.variable_scope(\"foo\", reuse=tf.AUTO_REUSE):\n",
    "        v = tf.get_variable(\"v\", [1])\n",
    "    return v\n",
    "v1 = foo()\n",
    "v2 = foo()\n",
    "assert v1 == v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [tf.clip_by_value](https://www.tensorflow.org/api_docs/python/tf/clip_by_value)\n",
    "\n",
    "将tensor剪切到特定的min与max之间. 其原型函数为:\n",
    "```bash\n",
    "tf.clip_by_value(\n",
    "    t,\n",
    "    clip_value_min,\n",
    "    clip_value_max,\n",
    "    name=None\n",
    ")\n",
    "```\n",
    "\n",
    "- `t`: 一个tensor;\n",
    "- `clip_value_min`: 剪切的最小值;\n",
    "- `clip_value_max`: 剪切的最大值;\n",
    "\n",
    "下面给出例子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"clip_by_value:0\", shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable([3.0, 2.0])\n",
    "b = tf.clip_by_value(a, 2.5, 2.7)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [tf.map_fn](https://www.tensorflow.org/api_docs/python/tf/map_fn)\n",
    "\n",
    "对`elems`在第0维度展开后组成的每一项运用`fn`函数. 其函数原型为:\n",
    "\n",
    "```bash\n",
    "tf.map_fn(\n",
    "    fn,\n",
    "    elems,\n",
    "    dtype=None,\n",
    "    parallel_iterations=10,\n",
    "    back_prop=True,\n",
    "    swap_memory=False,\n",
    "    infer_shape=True,\n",
    "    name=None\n",
    ")\n",
    "```\n",
    "\n",
    "- `fn`: 一个处理`elems`展开后组合的每一项的函数, 它的返回值结构应该与`dtype`描述的一样;\n",
    "- `elems`: 一个或者一组tensor, 它们在第0维度会展开, 并将组合结果传入`fn`进行计算;\n",
    "- `dtype`: 描述`fn`函数返回结果的结构;\n",
    "\n",
    "使用例子如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m1: [ 1  4  9 16 25 36]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "TensorArray dtype is int64 but Op is trying to write dtype int32.\n\t [[Node: map_3/while/TensorArrayWrite/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_INT32, _class=[\"loc:@map_3/while/mul\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](map_3/while/TensorArrayWrite/TensorArrayWriteV3/Enter, map_3/while/Identity_1, map_3/while/mul, map_3/while/Identity_2)]]\n\nCaused by op 'map_3/while/TensorArrayWrite/TensorArrayWriteV3', defined at:\n  File \"C:\\Python36\\Lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Python36\\Lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Python36\\Lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Python36\\Lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\Python36\\Lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-26-e09fcd5e679d>\", line 8, in <module>\n    alternate = tf.map_fn(lambda x: x[0] * x[1], elems, dtype=tf.int64)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\functional_ops.py\", line 459, in map_fn\n    maximum_iterations=n)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3232, in while_loop\n    return_same_structure)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2952, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2887, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3201, in <lambda>\n    body = lambda i, lv: (i + 1, orig_body(*lv))\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\functional_ops.py\", line 451, in compute\n    tas = [ta.write(i, value) for (ta, value) in zip(tas, flat_fn_values)]\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\functional_ops.py\", line 451, in <listcomp>\n    tas = [ta.write(i, value) for (ta, value) in zip(tas, flat_fn_values)]\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py\", line 118, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\tensor_array_ops.py\", line 842, in write\n    return self._implementation.write(index, value, name=name)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py\", line 118, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\tensor_array_ops.py\", line 276, in write\n    name=name)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 7963, in tensor_array_write_v3\n    flow_in=flow_in, name=name)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): TensorArray dtype is int64 but Op is trying to write dtype int32.\n\t [[Node: map_3/while/TensorArrayWrite/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_INT32, _class=[\"loc:@map_3/while/mul\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](map_3/while/TensorArrayWrite/TensorArrayWriteV3/Enter, map_3/while/Identity_1, map_3/while/mul, map_3/while/Identity_2)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: TensorArray dtype is int64 but Op is trying to write dtype int32.\n\t [[Node: map_3/while/TensorArrayWrite/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_INT32, _class=[\"loc:@map_3/while/mul\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](map_3/while/TensorArrayWrite/TensorArrayWriteV3/Enter, map_3/while/Identity_1, map_3/while/mul, map_3/while/Identity_2)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-e09fcd5e679d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0melems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0malternate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"m21:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malternate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;31m# 第二种用法\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0melems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m     \"\"\"\n\u001b[1;32m--> 680\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   4949\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4950\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 4951\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4952\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1289\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1291\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: TensorArray dtype is int64 but Op is trying to write dtype int32.\n\t [[Node: map_3/while/TensorArrayWrite/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_INT32, _class=[\"loc:@map_3/while/mul\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](map_3/while/TensorArrayWrite/TensorArrayWriteV3/Enter, map_3/while/Identity_1, map_3/while/mul, map_3/while/Identity_2)]]\n\nCaused by op 'map_3/while/TensorArrayWrite/TensorArrayWriteV3', defined at:\n  File \"C:\\Python36\\Lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Python36\\Lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Python36\\Lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Python36\\Lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\Python36\\Lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-26-e09fcd5e679d>\", line 8, in <module>\n    alternate = tf.map_fn(lambda x: x[0] * x[1], elems, dtype=tf.int64)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\functional_ops.py\", line 459, in map_fn\n    maximum_iterations=n)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3232, in while_loop\n    return_same_structure)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2952, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2887, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3201, in <lambda>\n    body = lambda i, lv: (i + 1, orig_body(*lv))\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\functional_ops.py\", line 451, in compute\n    tas = [ta.write(i, value) for (ta, value) in zip(tas, flat_fn_values)]\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\functional_ops.py\", line 451, in <listcomp>\n    tas = [ta.write(i, value) for (ta, value) in zip(tas, flat_fn_values)]\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py\", line 118, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\tensor_array_ops.py\", line 842, in write\n    return self._implementation.write(index, value, name=name)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py\", line 118, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\tensor_array_ops.py\", line 276, in write\n    name=name)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 7963, in tensor_array_write_v3\n    flow_in=flow_in, name=name)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"c:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): TensorArray dtype is int64 but Op is trying to write dtype int32.\n\t [[Node: map_3/while/TensorArrayWrite/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_INT32, _class=[\"loc:@map_3/while/mul\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](map_3/while/TensorArrayWrite/TensorArrayWriteV3/Enter, map_3/while/Identity_1, map_3/while/mul, map_3/while/Identity_2)]]\n"
     ]
    }
   ],
   "source": [
    "# 第一种用法\n",
    "elems = np.array([1, 2, 3, 4, 5, 6])\n",
    "squares = tf.map_fn(lambda x: x * x, elems)\n",
    "print(\"m1:\", squares.eval())\n",
    "\n",
    "# 第二种用法\n",
    "elems = (np.array([1, 2, 3]), np.array([-1, 1, -1]))\n",
    "alternate = tf.map_fn(lambda x: x[0] * x[1], elems, dtype=tf.int64)\n",
    "print(\"m21:\", alternate.eval())\n",
    "# 第二种用法\n",
    "elems = (np.array([[1], [2]]), np.array([[2], [3]]))\n",
    "alternate = tf.map_fn(lambda x: x[0] * x[1], elems, dtype=tf.int64)\n",
    "print(\"m22:\", alternate.eval())\n",
    "\n",
    "# 第三种用法\n",
    "elems = np.array([1, 2, 3])\n",
    "alternates = tf.map_fn(lambda x: (x, -x), elems, dtype=(tf.int64, tf.int64))\n",
    "print(\"m3:\")\n",
    "print(alternates[0].eval())\n",
    "print(alternates[1].eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [tf.gather](https://www.tensorflow.org/api_docs/python/tf/gather)\n",
    "\n",
    "根据索引从参数轴上收集切片. 其函数原型为:\n",
    "\n",
    "```bash\n",
    "tf.gather(\n",
    "    params,\n",
    "    indices,\n",
    "    validate_indices=None,\n",
    "    name=None,\n",
    "    axis=0\n",
    ")\n",
    "```\n",
    "- `params`: A tensor. 从哪个`tensor`上收集值, 其rank不能小于`axis+1`;\n",
    "- `indices`: A tensor. 在某个轴上收集数据的索引值, 它必须在`[0, params.shape[axis]`的范围内;\n",
    "- `axis`: A tensor. 在`params`的哪个维度上收集数据, 默认在第0维上收集;\n",
    "\n",
    "使用例子如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3]\n",
      "[[1 2]\n",
      " [5 6]]\n"
     ]
    }
   ],
   "source": [
    "# 从默认维度收集值\n",
    "temp = tf.constant([1, 2, 3, 4])\n",
    "a = tf.gather(temp, [0, 2])\n",
    "print(a.eval())\n",
    "\n",
    "# 从特定维度收集值\n",
    "temp1 = tf.constant([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "a1 =  tf.gather(temp1, [0, 1], axis=1)\n",
    "print(a1.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [tf.gradients](https://www.tensorflow.org/api_docs/python/tf/gradients)\n",
    "\n",
    "计算`ys`张量列表对于`xs`张量列表的偏导数. 其函数原型为:\n",
    "\n",
    "```bash\n",
    "tf.gradients(\n",
    "    ys,\n",
    "    xs,\n",
    "    grad_ys=None,\n",
    "    name='gradients',\n",
    "    colocate_gradients_with_ops=False,\n",
    "    gate_gradients=False,\n",
    "    aggregation_method=None,\n",
    "    stop_gradients=None\n",
    ")\n",
    "```\n",
    "- `ys`: 一个张量或者张量列表. \n",
    "- `xs`: 需要在那个tensor上求偏导, 是一个张量或者张量列表. 如果是列表, `ys`中每个y都要对`x`求偏导并相加或者该`x`位置该有的导数值.\n",
    "- `grad_ys`: 与`ys`有相同大小的张量或者张量列表, 对于`ys`中每个y都计算梯度.\n",
    "\n",
    "计算方式如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0 1.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(0.)\n",
    "b = a * 2\n",
    "c = a + b\n",
    "d = tf.gradients(c, [a, b])\n",
    "print(d[0].eval(), d[1].eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [tf.zeros_like](https://www.tensorflow.org/api_docs/python/tf/zeros_like)\n",
    "\n",
    "建立跟输入张量`dtype`与`shape`一样但所有元素都是0的张量. 其原型函数为:\n",
    "\n",
    "```bash\n",
    "tf.zeros_like(\n",
    "    tensor,\n",
    "    dtype=None,\n",
    "    name=None,\n",
    "    optimize=True\n",
    ")\n",
    "```\n",
    "\n",
    "- `tensor`: 一个张量;\n",
    "- `dtype`: 需要修改返回张量的`dtype`;\n",
    "\n",
    "使用例子如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0]\n",
      " [0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "a = tf.zeros_like(tensor) \n",
    "print(a.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [tf.stop_gradient](https://www.tensorflow.org/api_docs/python/tf/stop_gradient)\n",
    "\n",
    "在构建计算梯度的op时，此op防止将其输入的贡献考虑在内，其函数原型为：\n",
    "\n",
    "```bash\n",
    "tf.stop_gradient(\n",
    "    input,\n",
    "    name=None\n",
    ")\n",
    "```\n",
    "- `input`: 输入op，这个op关联的变量不会被最后计算梯度的时候考虑在内。\n",
    "\n",
    "其使用方式如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, <tf.Tensor 'gradients_1/Mul_10_grad/Mul_1:0' shape=() dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "w1 = tf.Variable(2.0)\n",
    "w2 = tf.Variable(2.0)\n",
    "\n",
    "a = tf.multiply(w1, 3.0)\n",
    "a_stoped = tf.stop_gradient(a)\n",
    "\n",
    "b = tf.multiply(a_stoped, w2)\n",
    "\n",
    "grads = tf.gradients(b, xs=[w1, w2])  # w1的梯度为None\n",
    "\n",
    "print(grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [tf.placeholder_with_default](https://www.tensorflow.org/api_docs/python/tf/placeholder_with_default)\n",
    "\n",
    "当没有输入feed的时候，使用`input`参数给的值，其函数原型为：\n",
    "\n",
    "```bash\n",
    "tf.placeholder_with_default(\n",
    "    input,\n",
    "    shape,\n",
    "    name=None\n",
    ")\n",
    "```\n",
    "\n",
    "- `input`: feed的默认值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [tf.multiply](https://www.tensorflow.org/api_docs/python/tf/math/multiply)\n",
    "\n",
    "实现两个张量元素级别相乘。其原型函数为：\n",
    "\n",
    "```bash\n",
    "tf.multiply(\n",
    "    x,\n",
    "    y,\n",
    "    name=None\n",
    ")\n",
    "```\n",
    "- `x`: 一个Tensor；\n",
    "- `y`: 一个Tensor，需要与`x`同一个type；\n",
    "\n",
    "注意：相乘最里层维度需要一样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: <tf.Variable 'Variable_42:0' shape=(2, 3) dtype=int32_ref>\n",
      "b: <tf.Variable 'Variable_43:0' shape=(3,) dtype=int32_ref>\n",
      "[[2 4 6]\n",
      " [2 4 6]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable([[1, 2, 3], [1, 2, 3]])\n",
    "b = tf.Variable([2, 2, 2])\n",
    "print(\"a:\", a)\n",
    "print(\"b:\", b)\n",
    "c = tf.multiply(a, b)\n",
    "init = tf.global_variables_initializer()\n",
    "init.run()\n",
    "print(c.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [tf.matmul](https://www.tensorflow.org/api_docs/python/tf/linalg/matmul)\n",
    "\n",
    "将两个张量相乘。其原型函数为：\n",
    "\n",
    "```bash\n",
    "tf.matmul(\n",
    "    a,\n",
    "    b,\n",
    "    transpose_a=False,\n",
    "    transpose_b=False,\n",
    "    adjoint_a=False,\n",
    "    adjoint_b=False,\n",
    "    a_is_sparse=False,\n",
    "    b_is_sparse=False,\n",
    "    name=None\n",
    ")\n",
    "```\n",
    "- `a`: 一个Tensor，Rank >= 1；\n",
    "- `b`: 一个Tensor，与`a`有相同的Type与Rank；\n",
    "- `transpose_a`: 如果为真，a在乘法之前被转置；\n",
    "- `transpose_b`: 如果为真，b在乘法之前被转置；\n",
    "- `a_is_sparse`: 如果为真，则将a视为稀疏矩阵；\n",
    "- `b_is_sparse`: 如果为真，则将b视为稀疏矩阵；\n",
    "\n",
    "注意：如果a或者b矩阵中有大量的0，可以设置相应的sparse标志为True，这样可以加快运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MatMul_5:0\", shape=(2, 2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(np.arange(1, 13, dtype=np.int32), shape=(2, 2, 3))\n",
    "b = tf.constant(np.arange(13, 25, dtype=np.int32), shape=(2, 3, 2))\n",
    "c = tf.matmul(a, b)\n",
    "print(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
