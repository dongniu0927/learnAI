{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类问题\n",
    "\n",
    "下面介绍了如何使用TF来做Mnist的分类问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获得数据\n",
    "\n",
    "使用`tf.keras.datasets`获取数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据用keras\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_data, train_label), (test_data, test_label) = mnist.load_data()\n",
    "\n",
    "def convert_to_one_hot(y, C):\n",
    "    return np.eye(C)[y.reshape(-1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data: (60000, 784)\n",
      "Shape of train label: (60000,)\n",
      "Label samples: [5 0 4 1 9]\n",
      "Shape of train label after processing: (60000, 10)\n",
      "Label samples after processing: [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_data/255.0, test_data/255.0\n",
    "train_data = train_data.reshape([-1, 784])\n",
    "print(\"Shape of train data:\", train_data.shape)\n",
    "print(\"Shape of train label:\", train_label.shape)\n",
    "print(\"Label samples:\", train_label[:5])\n",
    "train_label = convert_to_one_hot(train_label, 10)\n",
    "print(\"Shape of train label after processing:\", train_label.shape)\n",
    "print(\"Label samples after processing:\", train_label[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = tf.placeholder(tf.float32, [None, 784])\n",
    "ys = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layer(inputs, in_sz, out_sz, layer_index, activation_func=None):\n",
    "    Weights = tf.Variable(tf.random_normal((in_sz, out_sz)), name=\"weights_\"+str(layer_index), \n",
    "                          dtype=tf.float32)\n",
    "    biases = tf.Variable(tf.zeros(out_sz), name=\"biases_\"+str(layer_index))\n",
    "    a = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_func is None:\n",
    "        return a\n",
    "    else:\n",
    "        return activation_func(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = add_layer(xs, 784, 10, layer_index=1, activation_func=tf.nn.softmax)\n",
    "cross_entropy1 = -(ys*tf.log(pred))\n",
    "cross_entropy2 = tf.reduce_sum(cross_entropy1, reduction_indices=[1])\n",
    "cross_entropy3 = tf.reduce_mean(cross_entropy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Pred label: [[1.4511282e-09 6.2916195e-03 2.5573039e-09 6.6535590e-06 1.7740781e-08\n",
      "  5.9213598e-06 1.8403912e-01 2.9989583e-03 2.1696816e-01 5.8968949e-01]\n",
      " [4.1566297e-09 7.1455366e-07 1.5454352e-09 1.1043180e-05 2.5775649e-05\n",
      "  5.6889025e-06 1.3029569e-02 7.3704726e-08 2.3348871e-01 7.5343841e-01]\n",
      " [1.7582323e-20 4.9511345e-07 4.5375273e-07 9.6362371e-08 2.7559185e-05\n",
      "  1.5442931e-05 4.1148797e-07 3.3592040e-04 1.5096773e-06 9.9961805e-01]\n",
      " [5.3631347e-03 4.1131851e-05 5.5006766e-01 1.7698538e-03 2.7956554e-01\n",
      "  1.3417709e-01 8.7300014e-06 3.5056444e-05 1.5739401e-04 2.8814372e-02]\n",
      " [3.4017383e-10 7.7473550e-10 2.4801400e-03 4.2004888e-07 5.6926810e-06\n",
      "  1.9614922e-02 5.5557389e-11 7.7949947e-04 9.7711915e-01 1.3279511e-07]]\n",
      "Loss1: [[ 0.        0.        0.        0.        0.       12.036944  0.\n",
      "   0.        0.        0.      ]\n",
      " [19.298561  0.        0.        0.        0.        0.        0.\n",
      "   0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.       10.499175  0.        0.\n",
      "   0.        0.        0.      ]\n",
      " [ 0.       10.098728  0.        0.        0.        0.        0.\n",
      "   0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.       15.834458]]\n",
      "Loss2: [12.036944  19.298561  10.499175  ...  5.1142364  4.5150023  3.7936077]\n",
      "Loss3: 12.827538\n",
      "\n",
      "True label: [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Pred label: [[1.6594086e-08 1.9983598e-03 5.3737024e-09 2.9544732e-05 2.9072798e-08\n",
      "  1.0368609e-06 6.6107523e-01 3.2352475e-03 1.1928503e-01 2.1437547e-01]\n",
      " [5.2024797e-07 6.7627411e-07 1.1107051e-08 8.8768495e-05 1.1693810e-04\n",
      "  3.3128554e-06 1.5072429e-01 2.3331900e-07 2.1190107e-01 6.3716418e-01]\n",
      " [8.2500875e-20 3.0153873e-07 1.0310928e-06 2.7721882e-07 6.6638284e-05\n",
      "  7.4576233e-06 1.3107604e-06 4.7370687e-04 1.5973669e-06 9.9944764e-01]\n",
      " [1.3526532e-02 4.1100113e-05 6.8975890e-01 2.8645152e-03 2.5946736e-01\n",
      "  2.3208611e-02 1.4417746e-05 2.7684830e-05 1.7640102e-04 1.0914496e-02]\n",
      " [4.2420005e-09 8.1894486e-10 5.3599733e-03 2.0486905e-06 2.7777518e-05\n",
      "  5.3758230e-03 3.6647702e-10 1.9285254e-03 9.8730564e-01 2.8614153e-07]]\n",
      "Loss1: [[ 0.        0.        0.        0.        0.       13.779313  0.\n",
      "   0.        0.        0.      ]\n",
      " [14.46896   0.        0.        0.        0.        0.        0.\n",
      "   0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.        9.616231  0.        0.\n",
      "   0.        0.        0.      ]\n",
      " [ 0.       10.0995    0.        0.        0.        0.        0.\n",
      "   0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.       15.066779]]\n",
      "Loss2: [13.779313  14.46896    9.616231  ...  5.7982345  2.6562579  4.357807 ]\n",
      "Loss3: 11.346256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy3)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    batch_xs = train_data\n",
    "    batch_ys = train_label\n",
    "    for i in range(100):\n",
    "        sess.run(train, feed_dict={xs:batch_xs, ys:batch_ys})\n",
    "        if i % 50 == 0:\n",
    "            print(\"True label:\", batch_ys[:5])\n",
    "            print(\"Pred label:\", sess.run(pred[:5], \n",
    "                                          feed_dict={xs:batch_xs, ys:batch_ys}))\n",
    "            print(\"Loss1:\", sess.run(cross_entropy1[:5], \n",
    "                           feed_dict={xs:batch_xs, ys:batch_ys}))\n",
    "            print(\"Loss2:\", sess.run(cross_entropy2, \n",
    "                           feed_dict={xs:batch_xs, ys:batch_ys}))\n",
    "            print(\"Loss3:\", sess.run(cross_entropy3, \n",
    "                           feed_dict={xs:batch_xs, ys:batch_ys}))\n",
    "            print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
