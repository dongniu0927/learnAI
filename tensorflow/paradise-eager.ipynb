{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 6 12]\n",
      " [15 18]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tfe.Variable([[[1, 2], [2, 4], [3, 6]], [[4, 6], [5, 6], [6, 6]]])\n",
    "b = tf.reduce_sum(a, axis=[1])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: id=22, shape=(3, 2), dtype=int32, numpy=\n",
      "array([[1, 2],\n",
      "       [2, 4],\n",
      "       [3, 6]])>, <tf.Tensor: id=23, shape=(3, 2), dtype=int32, numpy=\n",
      "array([[4, 6],\n",
      "       [5, 6],\n",
      "       [6, 6]])>]\n"
     ]
    }
   ],
   "source": [
    "a = tfe.Variable([[[1, 2], [2, 4], [3, 6]], [[4, 6], [5, 6], [6, 6]]])\n",
    "b = tf.unstack(a, axis=0,num=2)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1]\n",
      "  [2]]\n",
      "\n",
      " [[3]\n",
      "  [4]]], shape=(2, 2, 1), dtype=int32)\n",
      "[<tf.Tensor: id=45, shape=(2, 1), dtype=int32, numpy=\n",
      "array([[1],\n",
      "       [3]])>, <tf.Tensor: id=46, shape=(2, 1), dtype=int32, numpy=\n",
      "array([[2],\n",
      "       [4]])>]\n"
     ]
    }
   ],
   "source": [
    "a = [tfe.Variable([[1], [2]]), tfe.Variable([[3], [4]])]  \n",
    "c = tf.stack(a)  # t * bsz * embed_sz\n",
    "d = tf.unstack(c, axis=1)\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 1)\n",
      "tf.Tensor(\n",
      "[[[ 4  4]\n",
      "  [ 3  6]]\n",
      "\n",
      " [[ 8  8]\n",
      "  [ 5 10]]\n",
      "\n",
      " [[12 12]\n",
      "  [ 7 14]]], shape=(3, 2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tfe.Variable([[[2], [3]], [[4], [5]], [[6], [7]]])\n",
    "print(a.shape)\n",
    "b = tfe.Variable([[2, 2], [1, 2]])\n",
    "c = a*b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "tf.Tensor([[1. 2. 3.]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]], shape=(4, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [1. 2. 3.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tfe.Variable([1, 2, 3], dtype=tf.float32)\n",
    "print(a[0])\n",
    "a = tf.expand_dims(a, axis=0)\n",
    "print(a)\n",
    "a= tf.tile(a, multiples=[2, 1])\n",
    "b = tf.zeros((2, 3), dtype=tf.float32)\n",
    "print(tf.concat([a, b], axis=0))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tfe.Variable([[1, 2, 3], [4, 5, 6]], dtype=tf.float32)\n",
    "b = tfe.Variable([1, 1.0, 1])\n",
    "print(a*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.00785409]\n",
      "  [ 0.7811947 ]\n",
      "  [-0.00587629]]\n",
      "\n",
      " [[-0.02495352]\n",
      "  [ 1.3893217 ]\n",
      "  [ 0.48354235]]], shape=(2, 3, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[0.23790939]\n",
      "  [0.5237103 ]\n",
      "  [0.23838039]]\n",
      "\n",
      " [[0.14757335]\n",
      "  [0.6070435 ]\n",
      "  [0.2453832 ]]], shape=(2, 3, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.23320317]\n",
      " [-0.8172093 ]], shape=(2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random_normal((2, 3, 1))  # (bsz, time_steps, embed_sz)\n",
    "b = tf.random_normal((2, 3, 1))\n",
    "c = tf.nn.softmax(a*b, axis=1)\n",
    "print(a*b)\n",
    "print(c)\n",
    "print(tf.reduce_sum(a*c, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]], shape=(5, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tfe.Variable([[1, 2, 3], [4, 5, 6]], dtype=tf.float32)\n",
    "c = tf.pad(a, [[0, 3], [0, 0]])\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.40760595 0.40760595], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tfe.Variable([[1, 2, 3], [4, 5, 6]], dtype=tf.float32)\n",
    "b = tfe.Variable([[0, 0, 1], [0, 0, 1]], dtype=tf.float32)\n",
    "c= tf.nn.softmax_cross_entropy_with_logits(logits=a, labels=b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[4. 4. 4.]\n",
      " [4. 6. 7.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tfe.Variable([[2, 2.0, 2], [3, 4, 5]])\n",
    "b = tfe.Variable([[2, 2.0, 2], [1, 2, 2]])\n",
    "print(a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ -0.87053347  -3.067144     4.8814006 ]\n",
      " [ -4.0611258  -13.857167     7.699502  ]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tfe.Variable([[ -1.8705335,  -5.067144,    1.8814006],\n",
    " [ -6.0611258, -15.857167,    5.699502 ]])\n",
    "b = tfe.Variable([[1., 2., 3.],\n",
    " [2. ,2. ,2.]])\n",
    "c = a + b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
      "array([[1, 2, 3],\n",
      "       [4, 5, 6]])>\n",
      "<tf.Variable 'Variable:0' shape=(2, 1) dtype=int32, numpy=\n",
      "array([[1],\n",
      "       [2]])>\n",
      "tf.Tensor(\n",
      "[[ 1  2  3]\n",
      " [ 8 10 12]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tfe.Variable([[1, 2, 3], [4, 5, 6]])\n",
    "b = tfe.Variable([[1], [2]])\n",
    "print(a)\n",
    "print(b)\n",
    "print(a*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 3, 2) dtype=int32, numpy=\n",
      "array([[[1, 2],\n",
      "        [2, 3],\n",
      "        [3, 3]],\n",
      "\n",
      "       [[4, 1],\n",
      "        [5, 1],\n",
      "        [6, 1]]])>\n",
      "tf.Tensor(\n",
      "[[ 6  8]\n",
      " [15  3]], shape=(2, 2), dtype=int32)\n",
      "[<tf.Tensor: id=3606, shape=(2, 2), dtype=int32, numpy=\n",
      "array([[1, 2],\n",
      "       [4, 1]])>, <tf.Tensor: id=3607, shape=(2, 2), dtype=int32, numpy=\n",
      "array([[2, 3],\n",
      "       [5, 1]])>, <tf.Tensor: id=3608, shape=(2, 2), dtype=int32, numpy=\n",
      "array([[3, 3],\n",
      "       [6, 1]])>]\n"
     ]
    }
   ],
   "source": [
    "a = tfe.Variable([[[1, 2], [2, 3], [3, 3]], [[4, 1], [5, 1], [6, 1]]])\n",
    "print(a)\n",
    "print(tf.reduce_sum(a, 1))\n",
    "print(tf.unstack(a, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Could not find valid device for node name: \"Softmax\"\nop: \"Softmax\"\ninput: \"dummy_input\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_INT32\n  }\n}\n [Op:Softmax]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-2952b07390d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    452\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m                 instructions)\n\u001b[1;32m--> 454\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    456\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32mc:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36msoftmax\u001b[1;34m(logits, axis, name, dim)\u001b[0m\n\u001b[0;32m   1736\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1738\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_nn_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1740\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m_softmax\u001b[1;34m(logits, compute_op, dim, name)\u001b[0m\n\u001b[0;32m   1671\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1672\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_last_dim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1673\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcompute_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1675\u001b[0m   \u001b[1;31m# If dim is the last dimension, simply reshape the logits to a matrix and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36msoftmax\u001b[1;34m(logits, name)\u001b[0m\n\u001b[0;32m   7693\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7694\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7695\u001b[1;33m       \u001b[0m_six\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dongn\\workon_home\\py3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Could not find valid device for node name: \"Softmax\"\nop: \"Softmax\"\ninput: \"dummy_input\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_INT32\n  }\n}\n [Op:Softmax]"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
