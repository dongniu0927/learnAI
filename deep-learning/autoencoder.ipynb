{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自编码器Autoencoder\n",
    "\n",
    "自编码器是一种**数据压缩**算法，其网络结构如下所示：\n",
    "\n",
    "![ae1](./resources/ae1.jpeg)\n",
    "\n",
    "输入图片通过一个Encoder结构变成一个**压缩的表征**，再通过Decoder重建输入来训练网络。形式化的表述为：\n",
    "\n",
    "> $h = f(x), \\ r=g(h)$\n",
    "\n",
    "上面$x$代表输入，$f$是一个编码器，$h$是压缩表征，$g$是一个解码器，$r$是重建的输入，一般$f$和$g$都是通过**神经网络**来实现，比如下面就是一种AE网络：\n",
    "\n",
    "![ae2](./resources/ae2.jpg)\n",
    "\n",
    "上面前两层是编码层，中间层为表征层，后两层为解码层。通过比较输出层与输入层的相似性来构造Loss函数，再做反向传播。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意的是：\n",
    "\n",
    "- AE是**数据相关**的，它只能压缩那些与训练数据类似的数据；\n",
    "- AE是**有损**的，解压缩的输出与原来的输入相比是退化的；\n",
    "- AE是**自监督**的，其标签产生于自输入的数据；\n",
    "- AE关注的不是重建的效果，而是如何学习到高级的抽象**特征表示**；\n",
    "\n",
    "主要应用：\n",
    "\n",
    "- 数据去燥\n",
    "- 可视化降维"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "\n",
    "- [Autoencoder基本操作及其Tensorflow实现](https://www.cnblogs.com/rhyswang/p/8859068.html)\n",
    "- [深度学习之自编码器AutoEncoder](https://blog.csdn.net/marsjhao/article/details/73480859)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
